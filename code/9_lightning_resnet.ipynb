{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, use_1d=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1)\n",
    "        if use_1d:\n",
    "            self.conv3 = nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(out_dim)\n",
    "        self.bn2 = nn.BatchNorm2d(out_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "def resnet_block(in_dim, out_dim, blocks, first_block=False):\n",
    "    blk = []\n",
    "    for i in range(blocks):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_dim, out_dim,\n",
    "                                use_1d=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_dim, out_dim))\n",
    "    return blk\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),# (1, 224, 224) -> (64, 112, 112)\n",
    "                                nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)# (64, 56, 56)\n",
    "                                )\n",
    "        self.b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True)) #(64, 56, 56)\n",
    "        self.b3 = nn.Sequential(*resnet_block(64, 128, 2)) #(128, 28, 28)\n",
    "        self.b4 = nn.Sequential(*resnet_block(128, 256, 2)) #(256, 14, 14)\n",
    "        self.b5 = nn.Sequential(*resnet_block(256, 512, 2)) #(512, 7, 7)\n",
    "\n",
    "        self.net = nn.Sequential(self.b1, self.b2, self.b3,\n",
    "                                 self.b4, self.b5,\n",
    "                                 nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                 nn.Flatten(),\n",
    "                                 nn.Linear(512, 10))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "trans = transforms.Compose([transforms.Resize(224), transforms.ToTensor()])\n",
    "\n",
    "full_train_data = torchvision.datasets.FashionMNIST(\n",
    "    \"./dataset\", train=True, transform=trans, download=False\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    \"./dataset\", train=False, transform=trans, download=False\n",
    ")\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "train_size = int(0.9 * len(full_train_data))\n",
    "valid_size = len(full_train_data) - train_size\n",
    "train_data, valid_data = data.random_split(full_train_data, [train_size, valid_size])\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=648, shuffle=True, num_workers=12)\n",
    "valid_loader = data.DataLoader(valid_data, batch_size=648, shuffle=False, num_workers=12)\n",
    "test_loader = data.DataLoader(test_data, batch_size=648, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pl_resnet(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_params, optimizer_name, optimizer_params):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = ResNet()\n",
    "        # 有params再加进去\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.predictions = []\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            optimizer = torch.optim.AdamW(self.parameters(), **self.hparams.optimizer_params)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(self.parameters(), **self.hparams.optimizer_params)\n",
    "        \n",
    "        scheduler = {\n",
    "            \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer=optimizer,\n",
    "                mode='min',\n",
    "                factor=0.1,\n",
    "                patience=5,\n",
    "            ),\n",
    "            \"monitor\": \"valid_acc\",\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self.model(X)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=-1) == y).float().mean()\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_hat = self.model(X)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        acc = (y_hat.argmax(dim=-1) == y).float().mean()\n",
    "        self.log(\"valid_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"valid_loss\", loss, logger=True)\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch # 由于这里使用的是fashion mnist，test有label，正常情况用X = batch就行了，为了模拟无label，我这里的y没有用\n",
    "        y_hat = self.model(X)\n",
    "        y_hat = y_hat.argmax(dim=-1).cpu().numpy()\n",
    "        self.predictions.append(y_hat)\n",
    "        return {\"prediction\": y_hat}\n",
    "    \n",
    "    def on_test_end(self):\n",
    "        import pandas as pd\n",
    "        predictions = [item for sublist in self.predictions for item in sublist]\n",
    "        df = pd.DataFrame({\n",
    "            \"prediction\": predictions,})\n",
    "        df.to_csv(\"./result.csv\")\n",
    "    \n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     train_acc = self.trainer.callback_metrics.get(\"train_acc\")\n",
    "    #     valid_acc = self.trainer.callback_metrics.get(\"valid_acc\")\n",
    "    #     print(\"train_acc: \", train_acc, \"\\t valid_acc: \", valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "logger = TensorBoardLogger(\"logs\", name=\"lightning_resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "def train(model_dir,loader_dict, model_config):\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=model_dir,\n",
    "        monitor=\"valid_acc\",\n",
    "        mode=\"max\",\n",
    "        verbose=True,\n",
    "        save_weights_only=True,\n",
    "        filename=\"resnet_epoch-{epoch:02d}-acc-{valid_acc:.4f}-loss-{val_loss:.4f}\",\n",
    "    )\n",
    "    lr_callback = LearningRateMonitor(\"epoch\")\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        callbacks=[checkpoint_callback, lr_callback],\n",
    "    )\n",
    "    trainer.logger._log_graph = True\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    model = pl_resnet(**model_config)\n",
    "    trainer.fit(model, loader_dict[\"train_loader\"], loader_dict[\"valid_loader\"])\n",
    "    # 训练完成\n",
    "    model = pl_resnet.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "\n",
    "    valid_result = trainer.validate(model, loader_dict[\"valid_loader\"])\n",
    "    trainer.test(model, loader_dict[\"test_loader\"])\n",
    "    result = {\"valid\": valid_result[0][\"valid_acc\"]}\n",
    "\n",
    "    return model, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/zhoujiefeng/miniconda3/envs/dive/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/zhoujiefeng/wjy/my_lightning/models/resnet exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | ResNet           | 11.2 M | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.714    Total estimated model params size (MB)\n",
      "58        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/zhoujiefeng/miniconda3/envs/dive/lib/python3.12/site-packages/pytorch_lightning/loggers/tensorboard.py:195: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 84/84 [00:41<00:00,  2.05it/s, v_num=1, train_loss=0.789, valid_acc=0.665, train_acc=0.552]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 84: 'valid_acc' reached 0.66500 (best 0.66500), saving model to '/home/zhoujiefeng/wjy/my_lightning/models/resnet/resnet_epoch-epoch=00-acc-valid_acc=0.6650-loss-val_loss=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 84/84 [00:41<00:00,  2.04it/s, v_num=1, train_loss=0.419, valid_acc=0.699, train_acc=0.821]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 168: 'valid_acc' reached 0.69900 (best 0.69900), saving model to '/home/zhoujiefeng/wjy/my_lightning/models/resnet/resnet_epoch-epoch=01-acc-valid_acc=0.6990-loss-val_loss=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 84/84 [00:41<00:00,  2.03it/s, v_num=1, train_loss=0.341, valid_acc=0.703, train_acc=0.857]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 252: 'valid_acc' reached 0.70350 (best 0.70350), saving model to '/home/zhoujiefeng/wjy/my_lightning/models/resnet/resnet_epoch-epoch=02-acc-valid_acc=0.7035-loss-val_loss=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 84/84 [00:41<00:00,  2.02it/s, v_num=1, train_loss=0.304, valid_acc=0.765, train_acc=0.880]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 336: 'valid_acc' reached 0.76483 (best 0.76483), saving model to '/home/zhoujiefeng/wjy/my_lightning/models/resnet/resnet_epoch-epoch=03-acc-valid_acc=0.7648-loss-val_loss=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 84/84 [00:41<00:00,  2.00it/s, v_num=1, train_loss=0.267, valid_acc=0.475, train_acc=0.893]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 420: 'valid_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 84/84 [00:42<00:00,  2.00it/s, v_num=1, train_loss=0.275, valid_acc=0.743, train_acc=0.904]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 504: 'valid_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 84/84 [00:41<00:00,  2.01it/s, v_num=1, train_loss=0.265, valid_acc=0.812, train_acc=0.910]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 588: 'valid_acc' reached 0.81250 (best 0.81250), saving model to '/home/zhoujiefeng/wjy/my_lightning/models/resnet/resnet_epoch-epoch=06-acc-valid_acc=0.8125-loss-val_loss=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 84/84 [00:41<00:00,  2.03it/s, v_num=1, train_loss=0.189, valid_acc=0.591, train_acc=0.919]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 672: 'valid_acc' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 84/84 [00:41<00:00,  2.02it/s, v_num=1, train_loss=0.222, valid_acc=0.819, train_acc=0.922]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 756: 'valid_acc' reached 0.81867 (best 0.81867), saving model to '/home/zhoujiefeng/wjy/my_lightning/models/resnet/resnet_epoch-epoch=08-acc-valid_acc=0.8187-loss-val_loss=0.0000.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 84/84 [00:41<00:00,  2.04it/s, v_num=1, train_loss=0.221, valid_acc=0.878, train_acc=0.927]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 840: 'valid_acc' reached 0.87817 (best 0.87817), saving model to '/home/zhoujiefeng/wjy/my_lightning/models/resnet/resnet_epoch-epoch=09-acc-valid_acc=0.8782-loss-val_loss=0.0000.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 84/84 [00:41<00:00,  2.03it/s, v_num=1, train_loss=0.221, valid_acc=0.878, train_acc=0.927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 10/10 [00:01<00:00,  6.88it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        valid_acc            0.878166675567627\n",
      "       valid_loss           0.33242717385292053\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 16/16 [00:02<00:00,  5.92it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./models/resnet\"\n",
    "\n",
    "loader_dict = {\n",
    "    \"train_loader\": train_loader,\n",
    "    \"valid_loader\": valid_loader,\n",
    "    \"test_loader\": test_loader,\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    \"model_name\": \"resnet\",\n",
    "    \"model_params\": None,\n",
    "    \"optimizer_name\": \"Adam\",\n",
    "    \"optimizer_params\": {\n",
    "        \"lr\": 1e-2,\n",
    "        \"weight_decay\": 1e-4,\n",
    "    }\n",
    "}\n",
    "\n",
    "model, result = train(model_dir, loader_dict, model_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
