{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic(w, b, num_example):\n",
    "    x = torch.normal(0, 1, (num_example, len(w)))\n",
    "    y = torch.matmul(x, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return x, y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意这里由于w是(dim, )的形式的，通过matmul得到的结果如果最终是(dim2)的形式，这个时候就可以将得到的结果进行reshape或者unsqueeze(1)来得到原本的维度(dim2, 1)\n",
    "> 如果没有reshape，那么在后续计算loss的时候，就会出错！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2. ,-3.4])\n",
    "true_b = 4.2\n",
    "num_example = 100\n",
    "\n",
    "feature, label = synthetic(true_w, true_b, num_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.1937,  0.2569],\n",
      "        [-0.1107, -0.4911],\n",
      "        [-0.8582,  0.0117],\n",
      "        [ 0.2713,  0.1854],\n",
      "        [ 0.8541,  1.0712],\n",
      "        [-0.5864,  1.0406],\n",
      "        [-1.1718, -0.2595],\n",
      "        [ 0.4299,  0.0717],\n",
      "        [ 0.3884,  0.2556],\n",
      "        [ 0.4986,  0.1399],\n",
      "        [ 0.3160,  0.3370],\n",
      "        [-1.3017,  1.5444],\n",
      "        [ 0.2750,  0.7689],\n",
      "        [ 0.1014, -0.2367],\n",
      "        [-0.6712,  0.3421],\n",
      "        [-2.0136,  0.0294],\n",
      "        [-0.4362,  0.0975],\n",
      "        [ 1.1925, -0.1259],\n",
      "        [-0.8901,  2.2032],\n",
      "        [-0.5416,  0.5166],\n",
      "        [-0.3713, -0.6396],\n",
      "        [ 0.5461, -1.4385],\n",
      "        [-0.3279, -0.7228],\n",
      "        [ 0.6339,  0.7199],\n",
      "        [ 0.0355, -0.2025],\n",
      "        [-0.2110,  0.8533],\n",
      "        [ 0.3769, -0.6264],\n",
      "        [-0.6898,  2.0465],\n",
      "        [-0.2963, -0.5493],\n",
      "        [ 1.7837,  1.6195],\n",
      "        [-1.8109, -0.3877],\n",
      "        [ 0.5750, -0.5180],\n",
      "        [ 0.1041, -1.5523],\n",
      "        [-0.0190,  0.6119],\n",
      "        [-1.4385,  1.3321],\n",
      "        [ 0.1620,  0.0895],\n",
      "        [-0.5222, -0.2503],\n",
      "        [ 0.6808, -2.2393],\n",
      "        [-0.2338,  1.9469],\n",
      "        [-2.6251, -0.2464],\n",
      "        [ 0.8533,  0.5329],\n",
      "        [-0.3443,  1.1940],\n",
      "        [-0.1069, -0.8652],\n",
      "        [-0.8151,  0.1510],\n",
      "        [-0.5651,  0.5801],\n",
      "        [-1.5818,  0.7619],\n",
      "        [ 0.9408, -0.8135],\n",
      "        [ 1.5625, -2.1626],\n",
      "        [-0.7455,  0.1373],\n",
      "        [ 1.0471,  0.1514],\n",
      "        [-0.0086,  0.7994],\n",
      "        [ 0.1685,  1.7032],\n",
      "        [ 1.5198,  0.8109],\n",
      "        [ 0.9699,  0.3880],\n",
      "        [-0.8558, -0.2845],\n",
      "        [ 0.2651,  0.4407],\n",
      "        [-1.9252,  0.1941],\n",
      "        [-1.5061,  0.8529],\n",
      "        [ 0.1053, -0.2549],\n",
      "        [-1.6672, -0.3422],\n",
      "        [-1.0230, -0.9723],\n",
      "        [-0.1652,  0.7418],\n",
      "        [ 0.1717, -1.0391],\n",
      "        [ 0.3594, -0.8295],\n",
      "        [-0.2591,  0.5669],\n",
      "        [ 0.1818,  0.1947],\n",
      "        [ 0.2971,  0.6202],\n",
      "        [ 0.2297, -0.8031],\n",
      "        [-1.0919,  0.0501],\n",
      "        [-0.2390,  1.9970],\n",
      "        [ 0.3188, -1.2159],\n",
      "        [-1.2535, -0.8746],\n",
      "        [ 2.4538, -0.6899],\n",
      "        [-0.0289,  1.3222],\n",
      "        [-0.1751,  0.3837],\n",
      "        [ 0.0900,  0.7374],\n",
      "        [ 1.9338,  0.7535],\n",
      "        [ 1.7708, -0.8494],\n",
      "        [-0.2786,  1.4908],\n",
      "        [ 1.5231, -0.4827],\n",
      "        [-1.0609,  0.5651],\n",
      "        [-0.1457, -0.8654],\n",
      "        [ 1.5201,  0.9912],\n",
      "        [ 0.5928, -0.4158],\n",
      "        [-0.3078,  0.3054],\n",
      "        [-0.0606, -0.2818],\n",
      "        [-0.9958,  0.5333],\n",
      "        [ 1.5192, -0.5658],\n",
      "        [ 0.4050,  1.0015],\n",
      "        [-0.0349, -1.4413],\n",
      "        [ 0.8895,  0.1888],\n",
      "        [-0.1597, -1.6953],\n",
      "        [ 1.4990,  1.4100],\n",
      "        [ 0.1029,  0.1539],\n",
      "        [-0.9092, -0.6133],\n",
      "        [-1.9675,  0.2759],\n",
      "        [-0.5851, -1.6316],\n",
      "        [-0.2238, -1.1474],\n",
      "        [ 1.8374, -0.3683],\n",
      "        [ 1.6546, -1.9268]]), tensor([[ 2.9416],\n",
      "        [ 5.6517],\n",
      "        [ 2.4440],\n",
      "        [ 4.1237],\n",
      "        [ 2.2618],\n",
      "        [-0.5089],\n",
      "        [ 2.7186],\n",
      "        [ 4.8123],\n",
      "        [ 4.1027],\n",
      "        [ 4.7081],\n",
      "        [ 3.6924],\n",
      "        [-3.6625],\n",
      "        [ 2.1458],\n",
      "        [ 5.2068],\n",
      "        [ 1.7044],\n",
      "        [ 0.0772],\n",
      "        [ 2.9871],\n",
      "        [ 7.0005],\n",
      "        [-5.0852],\n",
      "        [ 1.3705],\n",
      "        [ 5.6390],\n",
      "        [10.1852],\n",
      "        [ 6.0122],\n",
      "        [ 3.0076],\n",
      "        [ 4.9827],\n",
      "        [ 0.8805],\n",
      "        [ 7.0849],\n",
      "        [-4.1558],\n",
      "        [ 5.4738],\n",
      "        [ 2.2550],\n",
      "        [ 1.8977],\n",
      "        [ 7.0882],\n",
      "        [ 9.6823],\n",
      "        [ 2.0840],\n",
      "        [-3.1977],\n",
      "        [ 4.2091],\n",
      "        [ 4.0030],\n",
      "        [13.1864],\n",
      "        [-2.8911],\n",
      "        [-0.2207],\n",
      "        [ 4.0885],\n",
      "        [-0.5457],\n",
      "        [ 6.9397],\n",
      "        [ 2.0517],\n",
      "        [ 1.0984],\n",
      "        [-1.5692],\n",
      "        [ 8.8361],\n",
      "        [14.6695],\n",
      "        [ 2.2303],\n",
      "        [ 5.7657],\n",
      "        [ 1.4446],\n",
      "        [-1.2445],\n",
      "        [ 4.4785],\n",
      "        [ 4.8359],\n",
      "        [ 3.4693],\n",
      "        [ 3.2361],\n",
      "        [-0.3037],\n",
      "        [-1.7140],\n",
      "        [ 5.2768],\n",
      "        [ 2.0268],\n",
      "        [ 5.4572],\n",
      "        [ 1.3494],\n",
      "        [ 8.0669],\n",
      "        [ 7.7279],\n",
      "        [ 1.7492],\n",
      "        [ 3.8947],\n",
      "        [ 2.6737],\n",
      "        [ 7.3810],\n",
      "        [ 1.8471],\n",
      "        [-3.0459],\n",
      "        [ 8.9724],\n",
      "        [ 4.6814],\n",
      "        [11.4438],\n",
      "        [-0.3434],\n",
      "        [ 2.5561],\n",
      "        [ 1.8635],\n",
      "        [ 5.4976],\n",
      "        [10.6274],\n",
      "        [-1.4187],\n",
      "        [ 8.8963],\n",
      "        [ 0.1456],\n",
      "        [ 6.8430],\n",
      "        [ 3.8484],\n",
      "        [ 6.8023],\n",
      "        [ 2.5461],\n",
      "        [ 5.0338],\n",
      "        [ 0.4038],\n",
      "        [ 9.1478],\n",
      "        [ 1.6073],\n",
      "        [ 9.0303],\n",
      "        [ 5.3434],\n",
      "        [ 9.6546],\n",
      "        [ 2.4054],\n",
      "        [ 3.8647],\n",
      "        [ 4.4605],\n",
      "        [-0.6755],\n",
      "        [ 8.5771],\n",
      "        [ 7.6671],\n",
      "        [ 9.1398],\n",
      "        [14.0569]]))\n"
     ]
    }
   ],
   "source": [
    "def data_iter(data_array:tuple, batch_size:int, is_train:bool =True):\n",
    "    dataset = data.TensorDataset(*data_array)\n",
    "    dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=is_train)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = data_iter((feature, label), batch_size=10)\n",
    "print((feature, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(2, 1))\n",
    "\n",
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, num_epoch, trainer, loss):\n",
    "    for epoch in range(num_epoch):\n",
    "        for X, y in dataloader:\n",
    "            y_pred = net(X)\n",
    "            l = loss(y_pred, y)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "        l = loss(net(feature), label)\n",
    "        print(f\"epoch {epoch+1}: loss={l.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 1: loss=9.330928802490234\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 2: loss=2.4862029552459717\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 3: loss=0.6652320623397827\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 4: loss=0.17829817533493042\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 5: loss=0.047800902277231216\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 6: loss=0.012915946543216705\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 7: loss=0.003526994027197361\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 8: loss=0.0010060706408694386\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 9: loss=0.00034105725353583694\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 10: loss=0.0001607694139238447\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 11: loss=0.00011543859727680683\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 12: loss=0.00010246622696286067\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 13: loss=9.930244414135814e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 14: loss=9.823910659179091e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 15: loss=9.805775334825739e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 16: loss=9.793246863409877e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 17: loss=9.789397881831974e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 18: loss=9.786869486561045e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 19: loss=9.78553289314732e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 20: loss=9.784721623873338e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 21: loss=9.787188173504546e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 22: loss=9.789141040528193e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 23: loss=9.786121518118307e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 24: loss=9.791199408937246e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 25: loss=9.788037277758121e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 26: loss=9.788751776795834e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 27: loss=9.7872361948248e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 28: loss=9.784889698494226e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 29: loss=9.785283327801153e-05\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 1])\n",
      "epoch 30: loss=9.786434384295717e-05\n"
     ]
    }
   ],
   "source": [
    "epoches = 30\n",
    "train(dataloader, epoches, trainer, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
