{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, train_loader, test_loader, epochs, lr, writer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    global_step = 0\n",
    "    test_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        train_num = train_right = test_num = test_right = 0\n",
    "        for X, y in tqdm(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = model(X)\n",
    "            l = criterion(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            writer.add_scalar(\"loss/train\", l.item(), global_step)\n",
    "            global_step += 1\n",
    "            train_num += len(y)\n",
    "            train_right += (y==y_hat.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                l = criterion(y_hat, y)\n",
    "                test_right += (y==y_hat.argmax(dim=1)).sum().item()\n",
    "                test_num += len(y)\n",
    "\n",
    "                writer.add_scalar(\"loss/test\", l.item(), test_step)\n",
    "                test_step += 1\n",
    "                \n",
    "        print(f\"accuracy/train: {train_right/train_num}\")\n",
    "        print(f\"aaccuracy/test: {test_right/test_num}\")\n",
    "        writer.add_scalars(\"acc\", {'train': train_right/train_num, 'test': test_right/test_num}, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, use_1d=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1)\n",
    "        if use_1d:\n",
    "            self.conv3 = nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(out_dim)\n",
    "        self.bn2 = nn.BatchNorm2d(out_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "def resnet_block(in_dim, out_dim, blocks, first_block=False):\n",
    "    blk = []\n",
    "    for i in range(blocks):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(in_dim, out_dim,\n",
    "                                use_1d=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(out_dim, out_dim))\n",
    "    return blk\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),# (1, 224, 224) -> (64, 112, 112)\n",
    "                                nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=3, stride=2, padding=1)# (64, 56, 56)\n",
    "                                )\n",
    "        self.b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True)) #(64, 56, 56)\n",
    "        self.b3 = nn.Sequential(*resnet_block(64, 128, 2)) #(128, 28, 28)\n",
    "        self.b4 = nn.Sequential(*resnet_block(128, 256, 2)) #(256, 14, 14)\n",
    "        self.b5 = nn.Sequential(*resnet_block(256, 512, 2)) #(512, 7, 7)\n",
    "\n",
    "        self.net = nn.Sequential(self.b1, self.b2, self.b3,\n",
    "                                 self.b4, self.b5,\n",
    "                                 nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                                 nn.Flatten(),\n",
    "                                 nn.Linear(512, 10))\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans = transforms.Compose([transforms.Resize(224), transforms.ToTensor()])\n",
    "trans = transforms.Compose([transforms.Resize(96), transforms.ToTensor()])\n",
    "train_data = torchvision.datasets.FashionMNIST(\"./dataset\", train=True, transform=trans, download=False)\n",
    "test_data = torchvision.datasets.FashionMNIST(\"./dataset\", train=False, transform=trans, download=False)\n",
    "\n",
    "batch_size = 512\n",
    "train_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.8337166666666667\n",
      "aaccuracy/test: 0.8773\n",
      "epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.9075166666666666\n",
      "aaccuracy/test: 0.881\n",
      "epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.9195666666666666\n",
      "aaccuracy/test: 0.9033\n",
      "epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.93355\n",
      "aaccuracy/test: 0.917\n",
      "epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.9404333333333333\n",
      "aaccuracy/test: 0.916\n",
      "epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.9473166666666667\n",
      "aaccuracy/test: 0.9222\n",
      "epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.9537333333333333\n",
      "aaccuracy/test: 0.927\n",
      "epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.9584666666666667\n",
      "aaccuracy/test: 0.9248\n",
      "epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:14<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.9687333333333333\n",
      "aaccuracy/test: 0.9241\n",
      "epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:15<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy/train: 0.97285\n",
      "aaccuracy/test: 0.919\n"
     ]
    }
   ],
   "source": [
    "model = ResNet()\n",
    "writer = SummaryWriter(log_dir=\"./resnet_log\")\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "train(model, train_loader, test_loader, epochs=10, lr=0.001, writer=writer)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./resnet.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
