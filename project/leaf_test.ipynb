{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finetune_resnet():\n",
    "    # 加载预训练的 ResNet50\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "    # 替换最后一层\n",
    "    in_feature = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "    nn.Linear(in_feature, 256), nn.BatchNorm1d(256), nn.ReLU(),\n",
    "    nn.Linear(256, 176)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping:  {'abies_concolor': 0, 'abies_nordmanniana': 1, 'acer_campestre': 2, 'acer_ginnala': 3, 'acer_griseum': 4, 'acer_negundo': 5, 'acer_palmatum': 6, 'acer_pensylvanicum': 7, 'acer_platanoides': 8, 'acer_pseudoplatanus': 9, 'acer_rubrum': 10, 'acer_saccharinum': 11, 'acer_saccharum': 12, 'aesculus_flava': 13, 'aesculus_glabra': 14, 'aesculus_hippocastamon': 15, 'aesculus_pavi': 16, 'ailanthus_altissima': 17, 'albizia_julibrissin': 18, 'amelanchier_arborea': 19, 'amelanchier_canadensis': 20, 'amelanchier_laevis': 21, 'asimina_triloba': 22, 'betula_alleghaniensis': 23, 'betula_jacqemontii': 24, 'betula_lenta': 25, 'betula_nigra': 26, 'betula_populifolia': 27, 'broussonettia_papyrifera': 28, 'carpinus_betulus': 29, 'carpinus_caroliniana': 30, 'carya_cordiformis': 31, 'carya_glabra': 32, 'carya_ovata': 33, 'carya_tomentosa': 34, 'castanea_dentata': 35, 'catalpa_bignonioides': 36, 'catalpa_speciosa': 37, 'cedrus_atlantica': 38, 'cedrus_deodara': 39, 'cedrus_libani': 40, 'celtis_occidentalis': 41, 'celtis_tenuifolia': 42, 'cercidiphyllum_japonicum': 43, 'cercis_canadensis': 44, 'chamaecyparis_pisifera': 45, 'chamaecyparis_thyoides': 46, 'chionanthus_retusus': 47, 'chionanthus_virginicus': 48, 'cladrastis_lutea': 49, 'cornus_florida': 50, 'cornus_kousa': 51, 'cornus_mas': 52, 'crataegus_crus-galli': 53, 'crataegus_laevigata': 54, 'crataegus_phaenopyrum': 55, 'crataegus_pruinosa': 56, 'crataegus_viridis': 57, 'cryptomeria_japonica': 58, 'diospyros_virginiana': 59, 'eucommia_ulmoides': 60, 'evodia_daniellii': 61, 'fagus_grandifolia': 62, 'ficus_carica': 63, 'fraxinus_nigra': 64, 'fraxinus_pennsylvanica': 65, 'ginkgo_biloba': 66, 'gleditsia_triacanthos': 67, 'gymnocladus_dioicus': 68, 'halesia_tetraptera': 69, 'ilex_opaca': 70, 'juglans_cinerea': 71, 'juglans_nigra': 72, 'juniperus_virginiana': 73, 'koelreuteria_paniculata': 74, 'larix_decidua': 75, 'liquidambar_styraciflua': 76, 'liriodendron_tulipifera': 77, 'maclura_pomifera': 78, 'magnolia_acuminata': 79, 'magnolia_denudata': 80, 'magnolia_grandiflora': 81, 'magnolia_macrophylla': 82, 'magnolia_stellata': 83, 'magnolia_tripetala': 84, 'magnolia_virginiana': 85, 'malus_baccata': 86, 'malus_coronaria': 87, 'malus_floribunda': 88, 'malus_hupehensis': 89, 'malus_pumila': 90, 'metasequoia_glyptostroboides': 91, 'morus_alba': 92, 'morus_rubra': 93, 'nyssa_sylvatica': 94, 'ostrya_virginiana': 95, 'oxydendrum_arboreum': 96, 'paulownia_tomentosa': 97, 'phellodendron_amurense': 98, 'picea_abies': 99, 'picea_orientalis': 100, 'picea_pungens': 101, 'pinus_bungeana': 102, 'pinus_cembra': 103, 'pinus_densiflora': 104, 'pinus_echinata': 105, 'pinus_flexilis': 106, 'pinus_koraiensis': 107, 'pinus_nigra': 108, 'pinus_parviflora': 109, 'pinus_peucea': 110, 'pinus_pungens': 111, 'pinus_resinosa': 112, 'pinus_rigida': 113, 'pinus_strobus': 114, 'pinus_sylvestris': 115, 'pinus_taeda': 116, 'pinus_thunbergii': 117, 'pinus_virginiana': 118, 'pinus_wallichiana': 119, 'platanus_acerifolia': 120, 'platanus_occidentalis': 121, 'populus_deltoides': 122, 'populus_grandidentata': 123, 'populus_tremuloides': 124, 'prunus_pensylvanica': 125, 'prunus_sargentii': 126, 'prunus_serotina': 127, 'prunus_serrulata': 128, 'prunus_subhirtella': 129, 'prunus_virginiana': 130, 'prunus_yedoensis': 131, 'pseudolarix_amabilis': 132, 'ptelea_trifoliata': 133, 'pyrus_calleryana': 134, 'quercus_acutissima': 135, 'quercus_alba': 136, 'quercus_bicolor': 137, 'quercus_cerris': 138, 'quercus_coccinea': 139, 'quercus_imbricaria': 140, 'quercus_macrocarpa': 141, 'quercus_marilandica': 142, 'quercus_michauxii': 143, 'quercus_montana': 144, 'quercus_muehlenbergii': 145, 'quercus_nigra': 146, 'quercus_palustris': 147, 'quercus_phellos': 148, 'quercus_robur': 149, 'quercus_shumardii': 150, 'quercus_stellata': 151, 'quercus_velutina': 152, 'quercus_virginiana': 153, 'robinia_pseudo-acacia': 154, 'salix_babylonica': 155, 'salix_caroliniana': 156, 'salix_matsudana': 157, 'salix_nigra': 158, 'sassafras_albidum': 159, 'staphylea_trifolia': 160, 'stewartia_pseudocamellia': 161, 'styrax_japonica': 162, 'taxodium_distichum': 163, 'tilia_americana': 164, 'tilia_cordata': 165, 'tilia_europaea': 166, 'tilia_tomentosa': 167, 'tsuga_canadensis': 168, 'ulmus_americana': 169, 'ulmus_glabra': 170, 'ulmus_parvifolia': 171, 'ulmus_procera': 172, 'ulmus_pumila': 173, 'ulmus_rubra': 174, 'zelkova_serrata': 175}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/0.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/1.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/2.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/3.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/4.jpg</td>\n",
       "      <td>maclura_pomifera</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18348</th>\n",
       "      <td>images/18348.jpg</td>\n",
       "      <td>aesculus_glabra</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18349</th>\n",
       "      <td>images/18349.jpg</td>\n",
       "      <td>liquidambar_styraciflua</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18350</th>\n",
       "      <td>images/18350.jpg</td>\n",
       "      <td>cedrus_libani</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18351</th>\n",
       "      <td>images/18351.jpg</td>\n",
       "      <td>prunus_pensylvanica</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18352</th>\n",
       "      <td>images/18352.jpg</td>\n",
       "      <td>quercus_montana</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18353 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                    label  label_id\n",
       "0          images/0.jpg         maclura_pomifera        78\n",
       "1          images/1.jpg         maclura_pomifera        78\n",
       "2          images/2.jpg         maclura_pomifera        78\n",
       "3          images/3.jpg         maclura_pomifera        78\n",
       "4          images/4.jpg         maclura_pomifera        78\n",
       "...                 ...                      ...       ...\n",
       "18348  images/18348.jpg          aesculus_glabra        14\n",
       "18349  images/18349.jpg  liquidambar_styraciflua        76\n",
       "18350  images/18350.jpg            cedrus_libani        40\n",
       "18351  images/18351.jpg      prunus_pensylvanica       125\n",
       "18352  images/18352.jpg          quercus_montana       144\n",
       "\n",
       "[18353 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./dataset/leaf/train.csv\")\n",
    "\n",
    "all_labels = sorted(set(train_df['label']))\n",
    "label2id = {label: idx for idx, label in enumerate(all_labels)}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "print(\"mapping: \", label2id)\n",
    "\n",
    "train_df['label_id'] = train_df['label'].map(label2id)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "class LeavesDataset(Dataset):\n",
    "    def __init__(self, image_path, labels, root_dir, trans):\n",
    "        super().__init__()\n",
    "        self.data_dir = root_dir\n",
    "        self.image_path_list = image_path\n",
    "        self.labels = labels\n",
    "        self.transform = trans\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_path_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_idx_path = os.path.join(self.data_dir, self.image_path_list[idx])\n",
    "        image = self.transform(Image.open(image_idx_path).convert(\"RGB\"))\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# def train(model, lr, epochs, train_loader, test_loader, writer, fold_i):\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     # device = torch.device(\"cpu\")\n",
    "#     model = model.to(device)\n",
    "#     global_step = 0\n",
    "#     test_step = 0\n",
    "#     optimer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "#     criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#     best_acc = 0.0\n",
    "    \n",
    "#     for epoch in tqdm(range(epochs)):\n",
    "#         train_right = 0\n",
    "#         test_right = 0\n",
    "#         train_num = 0\n",
    "#         test_num = 0\n",
    "#         model.train()\n",
    "#         for X, y in train_loader:\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             y_hat = model(X)\n",
    "#             l = criterion(y_hat, y)\n",
    "#             optimer.zero_grad()\n",
    "#             l.backward()\n",
    "#             optimer.step()\n",
    "#             train_right += (y==y_hat.argmax(dim=1)).sum().item()\n",
    "#             total_num += len(y)\n",
    "\n",
    "#             writer.add_scalar(f\"fold_{fold_i}/loss/train\", l.item(), global_step)\n",
    "#             global_step += 1\n",
    "            \n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             model.eval()\n",
    "#             for X, y in test_loader:\n",
    "#                 X, y = X.to(device), y.to(device)\n",
    "#                 y_hat = model(X)\n",
    "#                 l = criterion(y_hat, y)\n",
    "#                 test_right += (y==y_hat.argmax(dim=1)).sum().item()\n",
    "\n",
    "#                 writer.add_scalar(f\"fold_{fold_i}/loss/test\", l.item(), test_step)\n",
    "#                 test_step += 1\n",
    "        \n",
    "#         writer.add_scalar(f\"fold_{fold_i}/accuracy/train\", train_right/total_num, epoch)\n",
    "#         writer.add_scalar(f\"fold_{fold_i}/accuracy/test\", test_right/total_num, epoch)\n",
    "#         test_acc = test_right/total_num\n",
    "#         if test_acc > best_acc:\n",
    "#             best_acc = test_acc\n",
    "#             torch.save(model.state_dict(), f\"./models/best_model_fold{fold_i}.ckpt\")\n",
    "#             print(f\"Best model saved for fold {fold_i} at epoch {epoch+1} with Val Acc {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, lr, epochs, train_loader, test_loader, writer, fold_i):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [{'params': [param for name, param in model.named_parameters() if 'fc.' not in name]},\n",
    "        {'params': model.fc.parameters(), 'lr': 1e-4 * 10}],\n",
    "        lr=1e-4, weight_decay=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    global_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        train_num = train_right = test_num = test_right = 0\n",
    "        for X, y in tqdm(train_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = model(X)\n",
    "            l = criterion(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            writer.add_scalar(f\"fold_{fold_i}/loss/train\", l.item(), global_step)\n",
    "            global_step += 1\n",
    "            train_num += len(y)\n",
    "            train_right += (y==y_hat.argmax(dim=1)).sum().item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for X, y in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                l = criterion(y_hat, y)\n",
    "                test_right += (y==y_hat.argmax(dim=1)).sum().item()\n",
    "                test_num += len(y)\n",
    "\n",
    "                writer.add_scalar(f\"fold_{fold_i}/loss/test\", l.item(), test_step)\n",
    "                test_step += 1\n",
    "    \n",
    "        test_acc = test_right/test_num\n",
    "        print(f\"fold_{fold_i}/accuracy/train: {train_right/train_num}\")\n",
    "        print(f\"fold_{fold_i}/aaccuracy/test: {test_right/test_num}\")\n",
    "        writer.add_scalars(f\"fold_{fold_i}/acc\", {'train': train_right/train_num, 'test': test_right/test_num}, epoch)\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), f\"./models/best_model_fold{fold_i}.ckpt\")\n",
    "            print(f\"Best model saved for fold {fold_i} at epoch {epoch+1} with Val Acc {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:21<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.29579076420106254\n",
      "fold_1/aaccuracy/test: 0.4883949002942138\n",
      "Best model saved for fold 1 at epoch 1 with Val Acc 0.4884\n",
      "epoch: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:20<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.6912954638332652\n",
      "fold_1/aaccuracy/test: 0.7366786531546257\n",
      "Best model saved for fold 1 at epoch 2 with Val Acc 0.7367\n",
      "epoch: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:20<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.8626072742133224\n",
      "fold_1/aaccuracy/test: 0.8393265773128473\n",
      "Best model saved for fold 1 at epoch 3 with Val Acc 0.8393\n",
      "epoch: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:20<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.9257866775643645\n",
      "fold_1/aaccuracy/test: 0.88558352402746\n",
      "Best model saved for fold 1 at epoch 4 with Val Acc 0.8856\n",
      "epoch: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:20<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.951695954229669\n",
      "fold_1/aaccuracy/test: 0.9053612291598562\n",
      "Best model saved for fold 1 at epoch 5 with Val Acc 0.9054\n",
      "epoch: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:21<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.9663261136085002\n",
      "fold_1/aaccuracy/test: 0.9194181104936253\n",
      "Best model saved for fold 1 at epoch 6 with Val Acc 0.9194\n",
      "epoch: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:21<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.9735185941969758\n",
      "fold_1/aaccuracy/test: 0.9259561948349133\n",
      "Best model saved for fold 1 at epoch 7 with Val Acc 0.9260\n",
      "epoch: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:20<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.976706170821414\n",
      "fold_1/aaccuracy/test: 0.9375612945406996\n",
      "Best model saved for fold 1 at epoch 8 with Val Acc 0.9376\n",
      "epoch: 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:21<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.9770331017572538\n",
      "fold_1/aaccuracy/test: 0.9344557044785877\n",
      "epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:21<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1/accuracy/train: 0.9822639967306906\n",
      "fold_1/aaccuracy/test: 0.933801896044459\n",
      "Fold 2\n",
      "epoch: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 26/48 [00:12<00:10,  2.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     50\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m train(model\u001b[38;5;241m=\u001b[39mmodel, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, test_loader\u001b[38;5;241m=\u001b[39mval_loader, writer\u001b[38;5;241m=\u001b[39mwriter, fold_i\u001b[38;5;241m=\u001b[39mfold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, lr, epochs, train_loader, test_loader, writer, fold_i)\u001b[0m\n\u001b[1;32m     25\u001b[0m l\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 28\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/loss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, l\u001b[38;5;241m.\u001b[39mitem(), global_step)\n\u001b[1;32m     29\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     30\u001b[0m train_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"./log/leaves\")\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "train_trans = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.RandomRotation(degrees=90),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.RandomVerticalFlip(),\n",
    "            # torchvision.transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            # torchvision.transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.95, 1.05)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "test_trans = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((224, 224)),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    model = get_finetune_resnet()\n",
    "\n",
    "    t_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    v_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = LeavesDataset(\n",
    "        image_path=t_df['image'].tolist(),\n",
    "        labels=t_df['label_id'].tolist(),\n",
    "        root_dir=\"./dataset/leaf\",\n",
    "        trans=train_trans\n",
    "    )\n",
    "\n",
    "    val_dataset = LeavesDataset(\n",
    "        image_path=v_df['image'].tolist(),\n",
    "        labels=v_df['label_id'].tolist(),\n",
    "        root_dir=\"./dataset/leaf\",\n",
    "        trans=test_trans\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "    train(model=model, lr=0.001, epochs=10, train_loader=train_loader, test_loader=val_loader, writer=writer, fold_i=fold+1)\n",
    "    # model.load_state_dict(torch.load(\"./models/leaves_best_model_fold1.ckpt\"))\n",
    "    # test_right = 0\n",
    "    # test_num = 0\n",
    "    # model.to(device)\n",
    "    # with torch.no_grad():\n",
    "    #     model.eval()\n",
    "    #     for X, y in val_loader:\n",
    "    #         X, y = X.to(device), y.to(device)\n",
    "    #         y_hat = model(X)\n",
    "    #         l = criterion(y_hat, y)\n",
    "    #         test_right += (y==y_hat.argmax(dim=1)).sum().item()\n",
    "    #         test_num += len(y)\n",
    "    # print(test_right/test_num)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
